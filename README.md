# project_ampev

## ğŸ“Š Projeto AMPEV â€“ Pipeline de IngestÃ£o com Azure Databricks

### ğŸ§­ Executive Summary:

Este projeto implementa um pipeline de ingestÃ£o incremental utilizando Azure Databricks, Unity Catalog e Delta Lake, seguindo a arquitetura Medallion (Bronze â†’ Silver â†’ Gold).

A camada Bronze jÃ¡ estÃ¡ totalmente operacional, com:

- IngestÃ£o incremental via Auto Loader (cloudFiles)
- GovernanÃ§a com Unity Catalog
- Controle de schema explÃ­cito
- Metadados de ingestÃ£o
- ExecuÃ§Ã£o automatizada via Jobs
- Versionamento com GitHub (Databricks Repos)

### ğŸ—ï¸ Arquitetura:
```
Volumes (Landing Zone)
        â†“
Auto Loader (cloudFiles)
        â†“
Delta Tables (Bronze Layer - Unity Catalog)
        â†“
(Silver Layer - futura etapa)
```

### ğŸ“ Estrutura do Volume:

Volume utilizado:

> /Volumes/ampev/bronze/landings

**Estrutura organizada:**

```
landings/
â”‚
â”œâ”€â”€ estabelecimentos/
â”œâ”€â”€ pedidos/
â”‚
â”œâ”€â”€ samples/
â”‚   â”œâ”€â”€ estabelecimentos/
â”‚   â””â”€â”€ pedidos/
â”‚
â”œâ”€â”€ _schemas/
â”‚   â”œâ”€â”€ estabelecimentos/
â”‚   â””â”€â”€ pedidos/
â”‚
â””â”€â”€ _checkpoints/
    â”œâ”€â”€ estabelecimentos/
    â””â”€â”€ pedidos/
```

## ğŸ“¦ Dados Ingeridos
 ### ğŸ“„ estabelecimentos.csv

| Campo             | Tipo   |
| ----------------- | ------ |
| Local             | String |
| Email             | String |
| EstabelecimentoID | Long   |
| Telefone          | String |


### ğŸ“„ pedidos.csv:

| Campo              | Tipo                                |
| ------------------ | ----------------------------------- |
| PedidoID           | Long                                |
| EstabelecimentoID  | Long                                |
| Produto            | String                              |
| quantidade_vendida | Long                                |
| Preco_Unitario     | Double                              |
| data_venda         | String (futura conversÃ£o para Date) |



## âš™ï¸ Tecnologias Utilizadas:

- Azure Databricks
- Unity Catalog
- Delta Lake
- Auto Loader (cloudFiles)
- GitHub (via Databricks Repos)
- Jobs (Workflows)

## ğŸ”„ EstratÃ©gia de IngestÃ£o:

> Auto Loader separado por entidade:

- Cada entidade possui: 
        - Pasta exclusiva
        - SchemaLocation exclusivo
        - Checkpoint exclusivo
        - Tabela Delta exclusiva

```Isso evita mistura de dados e garante isolamento.```

> Schema congelado (bootstrap controlado):

Os schemas foram inferidos a partir de arquivos sample e posteriormente congelados usando StructType(...), garantindo:

- Controle de tipos
- Estabilidade do pipeline
- Evitar inferÃªncia automÃ¡tica incorreta
- Permitir validaÃ§Ã£o futura de mudanÃ§as de layout

## Metadados de ingestÃ£o explÃ­cito:

Durante o writeStream sÃ£o adicionadas colunas tÃ©cnicas:

- ```_ingest_ts``` â†’ timestamp da ingestÃ£o
- ```_source_file``` â†’ caminho do arquivo original (via _metadata.file_path)

### ğŸš€ ExecuÃ§Ã£o do Pipeline:

> Pipeline executado via Databricks Job agendado.

```
ConfiguraÃ§Ã£o recomendada:
Trigger: Scheduled
FrequÃªncia: a cada 10 minutos
Trigger type: availableNow=True
```

> Fluxo:

- Arquivo Ã© colocado na pasta landing
- Job executa
- Auto Loader processa apenas novos arquivos
- Dados sÃ£o gravados na Bronze
- Job encerra

## ğŸ” GovernanÃ§a (Unity Catalog)

As tabelas sÃ£o criadas em:

 - ampev.bronze.estabelecimentos
 - ampev.bronze.pedidos

## ğŸ” Auditoria do Pipeline:

Foi implementado script de auditoria automÃ¡tica para validaÃ§Ã£o de:

- ExistÃªncia da tabela
- Quantidade de registros
- PresenÃ§a de metadados
- HistÃ³rico Delta
- ExistÃªncia de checkpoint


## ğŸ§ª Controle de ExecuÃ§Ã£o:

O pipeline nÃ£o inicia se a pasta estiver vazia:

> has_files(path)

Isso evita:

- Erros de inferÃªncia
- CriaÃ§Ã£o de checkpoint vazio
- ExecuÃ§Ãµes desnecessÃ¡rias

## ğŸ”„ Controle de Versionamento:

IntegraÃ§Ã£o via Databricks Repos:

> Repos/<usuario>/<repositorio>


Fluxo:

- Clone do repositÃ³rio GitHub
- Commit & Push via UI do Databricks


## ğŸ“Œ Boas PrÃ¡ticas Aplicadas:

- SeparaÃ§Ã£o por entidade
- Schema explÃ­cito
- Uso de checkpoints dedicados
- Uso de _metadata.file_path
- ExecuÃ§Ã£o via Job
- Estrutura padronizada de diretÃ³rios
- Auditoria automatizada

## ğŸ“ˆ PrÃ³ximos Passos (Roadmap):

- Implementar camada Silver (join pedidos â†” estabelecimentos)
- NormalizaÃ§Ã£o de tipos (converter data_venda para DateType)
- Adicionar monitoramento via alertas
- Criar branch strategy (dev/main)

## ğŸ¯ Status Atual:

- âœ… Volume criado
- âœ… Estrutura organizada
- âœ… Auto Loader configurado
- âœ… Schema congelado
- âœ… WriteStream configurado
- âœ… Job configurado
- âœ… IntegraÃ§Ã£o com Git funcionando

Pipeline Bronze operacional.

# ğŸ“¦ Camada Silver â€” Fato Pedidos (SCD Type 2)

## ğŸ“Œ Objetivo

Construir a tabela `ampev.silver.fato_pedidos_scd2` aplicando:

- PadronizaÃ§Ã£o de schema
- Tipagem correta
- DeduplicaÃ§Ã£o por ingestÃ£o
- Controle de histÃ³rico via SCD Type 2
- Chave composta (`PedidoID`, `EstabelecimentoID`)
- Hash para detecÃ§Ã£o de mudanÃ§as

---

# ğŸ— Arquitetura

```
Bronze (raw)
    â†“
Staging (deduplicaÃ§Ã£o + padronizaÃ§Ã£o + hash)
    â†“
SCD2 (Delta Lake)
```

---

# ğŸ¥‰ Fonte Bronze

Tabela origem:

```sql
ampev.bronze.pedidos
```

ContÃ©m:
- Dados crus
- Metadados de ingestÃ£o (`_ingest_ts`, `_source_file`)

---

# ğŸ§¹ 1. Staging (PadronizaÃ§Ã£o e DeduplicaÃ§Ã£o)

### âœ” Tipagem aplicada

| Coluna | Tipo Final |
|---------|------------|
| PedidoID | BIGINT |
| EstabelecimentoID | BIGINT |
| Produto | STRING |
| quantidade_vendida | BIGINT |
| Preco_Unitario | DOUBLE |
| data_venda | DATE |

---

### âœ” DeduplicaÃ§Ã£o

Aplicado `row_number()` com janela:

```python
Window.partitionBy("PedidoID", "EstabelecimentoID")
      .orderBy(F.col("_ingest_ts").desc())
```

MantÃ©m apenas:

```
_rn = 1 â†’ versÃ£o mais recente por chave composta
```

---

# ğŸ” 2. Hash de Atributos

Criado `_attr_hash` com:

```python
F.sha2(
    F.concat_ws("||",
        Produto,
        quantidade_vendida,
        Preco_Unitario,
        data_venda
    ),
    256
)
```

### ğŸ¯ Objetivo

Detectar alteraÃ§Ãµes em qualquer atributo do pedido sem comparar coluna por coluna.

---

# ğŸ› 3. Estrutura da Tabela SCD2

```sql
CREATE TABLE ampev.silver.fato_pedidos_scd2 (
  surrogate_key BIGINT GENERATED ALWAYS AS IDENTITY,

  PedidoID BIGINT,
  EstabelecimentoID BIGINT,
  Produto STRING,
  quantidade_vendida BIGINT,
  Preco_Unitario DOUBLE,
  data_venda DATE,

  start_date DATE,
  end_date DATE,
  is_current BOOLEAN,

  _attr_hash STRING,
  _bronze_ingest_ts TIMESTAMP,
  _bronze_source_file STRING,
  _silver_ts TIMESTAMP
)
USING DELTA;
```

---

# ğŸ”„ 4. LÃ³gica SCD Type 2

## ğŸ“Œ Chave Composta

A chave de negÃ³cio Ã©:

```
(PedidoID, EstabelecimentoID)
```

---

## ğŸ†• Novos Registros

Quando nÃ£o existe versÃ£o atual:

```
_is_new = TRUE
```

â†’ Insere nova linha como:

- `start_date = current_date()`
- `end_date = 9999-12-31`
- `is_current = TRUE`

---

## ğŸ” Registros Alterados

Quando `_attr_hash` Ã© diferente:

1. Fecha versÃ£o atual:
   - `end_date = current_date() - 1`
   - `is_current = FALSE`

2. Insere nova versÃ£o com novos atributos.

---

# ğŸ“Š Exemplo de HistÃ³rico

| PedidoID | EstabelecimentoID | Produto | start_date | end_date | is_current |
|-----------|------------------|----------|------------|----------|------------|
| 1 | 1 | Cerveja | 2026-02-01 | 2026-02-10 | FALSE |
| 1 | 1 | Cerveja Premium | 2026-02-11 | 9999-12-31 | TRUE |

---

# ğŸ” Consulta de HistÃ³rico

```sql
SELECT *
FROM ampev.silver.fato_pedidos_scd2
WHERE PedidoID = 1
  AND EstabelecimentoID = 1
ORDER BY start_date;
```

---

# ğŸš€ BenefÃ­cios da ImplementaÃ§Ã£o

- HistÃ³rico completo de alteraÃ§Ãµes
- Rastreabilidade (bronze â†’ silver)
- Performance otimizada (comparaÃ§Ã£o por hash)
- Controle via `is_current`
- CompatÃ­vel com camadas Gold e Modelagem Dimensional

---

# âš  ConsideraÃ§Ãµes TÃ©cnicas

### 1ï¸âƒ£ Data Sentinela

`9999-12-31` Ã© utilizada como padrÃ£o para registros vigentes.

### 2ï¸âƒ£ ExecuÃ§Ã£o DiÃ¡ria

A lÃ³gica assume carga diÃ¡ria.  
Para cargas intradiÃ¡rias recomenda-se uso de `TIMESTAMP`.

### 3ï¸âƒ£ Performance

A comparaÃ§Ã£o Ã© feita apenas contra registros `is_current = TRUE`.

---

# ğŸ§  ConclusÃ£o

A implementaÃ§Ã£o do SCD Type 2 na tabela fato permite:

- Manter histÃ³rico completo
- Evitar sobrescrita de dados
- Garantir integridade temporal
- Suportar anÃ¡lises histÃ³ricas

---

**Autor:** Projeto AMPEV  
**Camada:** Silver  
**PadrÃ£o:** Delta Lake + SCD Type 2

ğŸ“ˆ Roadmap EstratÃ©gico
ğŸ”¹ PrÃ³xima Fase â€“ Silver Layer

ConversÃ£o data_venda para DateType

Join entre pedidos e estabelecimentos

Tratamento de dados invÃ¡lidos

DeduplicaÃ§Ã£o

ğŸ”¹ Fase Gold

KPIs

MÃ©tricas agregadas

Camada para BI / Power BI

ğŸ”¹ Melhorias Futuras

Alertas automÃ¡ticos

Testes de qualidade de dados

CI/CD com branches dev/main

Monitoramento de SLA