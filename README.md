# project_ampev

## ğŸ“Š Projeto AMPEV â€“ Pipeline de IngestÃ£o com Azure Databricks

### ğŸ§­ Executive Summary:

Este projeto implementa um pipeline de ingestÃ£o incremental utilizando Azure Databricks, Unity Catalog e Delta Lake, seguindo a arquitetura Medallion (Bronze â†’ Silver â†’ Gold).

A camada Bronze jÃ¡ estÃ¡ totalmente operacional, com:

- IngestÃ£o incremental via Auto Loader (cloudFiles)
- GovernanÃ§a com Unity Catalog
- Controle de schema explÃ­cito
- Metadados de ingestÃ£o
- ExecuÃ§Ã£o automatizada via Jobs
- Versionamento com GitHub (Databricks Repos)

### ğŸ—ï¸ Arquitetura:
```
Volumes (Landing Zone)
        â†“
Auto Loader (cloudFiles)
        â†“
Delta Tables (Bronze Layer - Unity Catalog)
        â†“
(Silver Layer - futura etapa)
```

### ğŸ“ Estrutura do Volume:

Volume utilizado:

> /Volumes/ampev/bronze/landings

**Estrutura organizada:**

```
landings/
â”‚
â”œâ”€â”€ estabelecimentos/
â”œâ”€â”€ pedidos/
â”‚
â”œâ”€â”€ samples/
â”‚   â”œâ”€â”€ estabelecimentos/
â”‚   â””â”€â”€ pedidos/
â”‚
â”œâ”€â”€ _schemas/
â”‚   â”œâ”€â”€ estabelecimentos/
â”‚   â””â”€â”€ pedidos/
â”‚
â””â”€â”€ _checkpoints/
    â”œâ”€â”€ estabelecimentos/
    â””â”€â”€ pedidos/
```

### ğŸ“¦ Dados Ingeridos
 ### ğŸ“„ estabelecimentos.csv

| Campo             | Tipo   |
| ----------------- | ------ |
| Local             | String |
| Email             | String |
| EstabelecimentoID | Long   |
| Telefone          | String |


### ğŸ“„ pedidos.csv:

| Campo              | Tipo                                |
| ------------------ | ----------------------------------- |
| PedidoID           | Long                                |
| EstabelecimentoID  | Long                                |
| Produto            | String                              |
| quantidade_vendida | Long                                |
| Preco_Unitario     | Double                              |
| data_venda         | String (futura conversÃ£o para Date) |



### âš™ï¸ Tecnologias Utilizadas:

- Azure Databricks
- Unity Catalog
- Delta Lake
- Auto Loader (cloudFiles)
- GitHub (via Databricks Repos)
- Jobs (Workflows)

### ğŸ”„ EstratÃ©gia de IngestÃ£o:

> Auto Loader separado por entidade:

- Cada entidade possui: 
        - Pasta exclusiva
        - SchemaLocation exclusivo
        - Checkpoint exclusivo
        - Tabela Delta exclusiva

```Isso evita mistura de dados e garante isolamento.```

> Schema congelado (bootstrap controlado):

Os schemas foram inferidos a partir de arquivos sample e posteriormente congelados usando StructType(...), garantindo:

- Controle de tipos
- Estabilidade do pipeline
- Evitar inferÃªncia automÃ¡tica incorreta
- Permitir validaÃ§Ã£o futura de mudanÃ§as de layout

### Metadados de ingestÃ£o explÃ­cito:

Durante o writeStream sÃ£o adicionadas colunas tÃ©cnicas:

- ```_ingest_ts``` â†’ timestamp da ingestÃ£o
- ```_source_file``` â†’ caminho do arquivo original (via _metadata.file_path)

### ğŸš€ ExecuÃ§Ã£o do Pipeline:

> Pipeline executado via Databricks Job agendado.

```
ConfiguraÃ§Ã£o recomendada:
Trigger: Scheduled
FrequÃªncia: a cada 10 minutos
Trigger type: availableNow=True
```

> Fluxo:

- Arquivo Ã© colocado na pasta landing
- Job executa
- Auto Loader processa apenas novos arquivos
- Dados sÃ£o gravados na Bronze
- Job encerra

### ğŸ” GovernanÃ§a (Unity Catalog)

As tabelas sÃ£o criadas em:

 - ampev.bronze.estabelecimentos
 - ampev.bronze.pedidos

### ğŸ” Auditoria do Pipeline:

Foi implementado script de auditoria automÃ¡tica para validaÃ§Ã£o de:

- ExistÃªncia da tabela
- Quantidade de registros
- PresenÃ§a de metadados
- HistÃ³rico Delta
- ExistÃªncia de checkpoint


### ğŸ§ª Controle de ExecuÃ§Ã£o:

O pipeline nÃ£o inicia se a pasta estiver vazia:

> has_files(path)

Isso evita:

- Erros de inferÃªncia
- CriaÃ§Ã£o de checkpoint vazio
- ExecuÃ§Ãµes desnecessÃ¡rias

## ğŸ”„ Controle de Versionamento:

IntegraÃ§Ã£o via Databricks Repos:

> Repos/<usuario>/<repositorio>


Fluxo:

- Clone do repositÃ³rio GitHub
- Commit & Push via UI do Databricks


### ğŸ“Œ Boas PrÃ¡ticas Aplicadas:

- SeparaÃ§Ã£o por entidade
- Schema explÃ­cito
- Uso de checkpoints dedicados
- Uso de _metadata.file_path
- ExecuÃ§Ã£o via Job
- Estrutura padronizada de diretÃ³rios
- Auditoria automatizada

### ğŸ“ˆ PrÃ³ximos Passos (Roadmap):

- Implementar camada Silver 
- NormalizaÃ§Ã£o de tipos (converter data_venda para DateType)
- Criar branch strategy (dev/main)

### ğŸ¯ Status Atual:

- âœ… Volume criado
- âœ… Estrutura organizada
- âœ… Auto Loader configurado
- âœ… Schema congelado
- âœ… WriteStream configurado
- âœ… Job configurado
- âœ… IntegraÃ§Ã£o com Git funcionando

Pipeline Bronze operacional.

### ğŸ“¦ Camada Silver â€” ImplementaÃ§Ã£o SCD Type 2

### Objetivo

Implementar controle de histÃ³rico (Slowly Changing Dimension Type 2) nas tabelas da camada Silver:

- `ampev.silver.dim_estabelecimentos_scd2`
- `ampev.silver.fato_pedidos_scd2`

A soluÃ§Ã£o garante:

- HistÃ³rico completo de alteraÃ§Ãµes
- Rastreabilidade Bronze â†’ Silver
- Controle temporal
- ComparaÃ§Ã£o eficiente via hash
- Compatibilidade com modelagem dimensional (Gold)

---

### ğŸ— Arquitetura Geral

```
Bronze (raw ingest)
        â†“
Staging (padronizaÃ§Ã£o + deduplicaÃ§Ã£o + hash)
        â†“
Silver SCD2 (Delta Lake)
```
---

### ğŸ¢ Tabela DimensÃ£o â€” Estabelecimentos (SCD2)

### Tabela:

```sql
ampev.silver.dim_estabelecimentos_scd2
```

### ğŸ”‘ Chave de NegÃ³cio:

```
EstabelecimentoID
```

### ğŸ§± Estrutura

```sql
CREATE TABLE ampev.silver.dim_estabelecimentos_scd2 (
  surrogate_key BIGINT GENERATED ALWAYS AS IDENTITY,

  EstabelecimentoID BIGINT,
  Local STRING,
  Email STRING,
  Telefone STRING,

  start_date DATE,
  end_date DATE,
  is_current BOOLEAN,

  _attr_hash STRING,
  _bronze_ingest_ts TIMESTAMP,
  _bronze_source_file STRING,
  _silver_ts TIMESTAMP
)
USING DELTA;
```

---

### ğŸ”„ LÃ³gica SCD2 â€” DimensÃ£o

### ğŸ†• Novo Estabelecimento
```
Quando '_is_new' = TRUE, significa que o 'EstabelecimentoID' ainda nÃ£o existe na dimensÃ£o (silver.dim_estabelecimentos_scd2).
Ou seja, estamos lidando com um registro totalmente novo, e nÃ£o com uma atualizaÃ§Ã£o.
```

- `_is_new = TRUE`
- Insere nova linha:
  - `start_date = current_date()` -> Data em que o registro passa a ser vÃ¡lido
  - `end_date = 9999-12-31` ->  -> Data futura simbÃ³lica indicando que o registro estÃ¡ ativo
  - `is_current = TRUE` -> Indica que esta Ã© a versÃ£o atual do estabelecimento

> No caso de um novo estabelecimento nÃ£o hÃ¡ histÃ³rico anterior. Ele jÃ¡ nasce como a versÃ£o vigente. Futuras alteraÃ§Ãµes gerarÃ£o novas > > > versÃµes, preservando essa original.  

---

### ğŸ” AlteraÃ§Ã£o de Atributo

```
Quando o '_attr_hash' Ã© diferente, significa que algum atributo relevante do estabelecimento foi alterado (ex: nome, cidade, categoria, etc.). Nesse caso, nÃ£o sobrescrevemos o registro antigo. Aplicamos a estratÃ©gia de SCD Type 2, preservando o histÃ³rico.
Se `_attr_hash` for diferente fecha a versÃ£o atual:  - `end_date = current_date() - 1` e  - `is_current se torna 'FALSE'
e insere nova versÃ£o com dados atualizados.
```
---

### ğŸ“Š Exemplo HistÃ³rico

| EstabelecimentoID | Email | start_date | end_date | is_current |
|------------------|--------|------------|----------|------------|
| 1 | antigo@email.com | 2026-02-01 | 2026-02-10 | FALSE |
| 1 | novo@email.com   | 2026-02-11 | 9999-12-31 | TRUE |

---

### ğŸ§¾ Tabela Fato â€” Pedidos (SCD2)

### Tabela

```sql
ampev.silver.fato_pedidos_scd2
```

### ğŸ”‘ Chave de NegÃ³cio (Composta)

```
(PedidoID, EstabelecimentoID)
```

---

### ğŸ§± Estrutura:

```sql
CREATE TABLE ampev.silver.fato_pedidos_scd2 (
  surrogate_key BIGINT GENERATED ALWAYS AS IDENTITY,

  PedidoID BIGINT,
  EstabelecimentoID BIGINT,
  Produto STRING,
  quantidade_vendida BIGINT,
  Preco_Unitario DOUBLE,
  data_venda DATE,

  start_date DATE,
  end_date DATE,
  is_current BOOLEAN,

  _attr_hash STRING,
  _bronze_ingest_ts TIMESTAMP,
  _bronze_source_file STRING,
  _silver_ts TIMESTAMP
)
USING DELTA;
```
---
### ğŸ§¹ Staging

```A etapa de staging serve para deixar a fonte â€œprontaâ€ antes de aplicar regras de negÃ³cio (ex: SCD2). Aqui a ideia Ã© padronizar, limpar e criar colunas tÃ©cnicas que facilitem o processamento.
```

- `Tipagem correta` -> Garanta que cada coluna esteja no tipo esperado (ex.: PedidoID/EstabelecimentoID como numÃ©rico, quantidade como inteiro/decimal, etc.). Isso evita erro de join, comparaÃ§Ã£o, agregaÃ§Ã£o e escrita.
- ConversÃ£o `data_venda` â†’ DATE
- DeduplicaÃ§Ã£o via `row_number()` com chave composta -> Como podem existir mÃºltiplas versÃµes do mesmo registro na Bronze (reprocessamento/ingestÃµes), vocÃª mantÃ©m apenas a versÃ£o mais recente.
- Hash dos atributos -> Crie um hash (ex.: _attr_hash) com os atributos de negÃ³cio relevantes (excluindo colunas tÃ©cnicas) para detectar mudanÃ§as de forma simples. Se o hash nÃ£o mudou â†’ sem alteraÃ§Ã£o real nos atributos. Se o hash mudou â†’ houve alteraÃ§Ã£o â†’ dispara SCD2 (fechar versÃ£o antiga e criar nova)

---

## ğŸ”„ LÃ³gica SCD2 â€” Fato

### ğŸ†• Novo Pedido

Um pedido Ã© considerado novo quando a chave do registro nÃ£o existe entre os registros vigentes (is_current = TRUE) da sua tabela fato SCD2 (ex.: silver.fato_pedidos_scd2). EntÃ£o Ã© inserido como versÃ£o vigente.

---

### ğŸ” Pedido Alterado

> Quando `_attr_hash` for diferente para um registro novo. Ocorer a fecha automÃ¡tica da versÃ£o atual e insere nova versÃ£o

---

## ğŸ“Š Exemplo HistÃ³rico

| PedidoID | EstabelecimentoID | Produto | start_date | end_date | is_current |
|----------|------------------|----------|------------|----------|------------|
| 1 | 1 | Cerveja | 2026-02-01 | 2026-02-10 | FALSE |
| 1 | 1 | Cerveja Premium | 2026-02-11 | 9999-12-31 | TRUE |

---

## ğŸ” Consultas de HistÃ³rico

### Estabelecimentos

```sql
SELECT *
FROM ampev.silver.dim_estabelecimentos_scd2
WHERE EstabelecimentoID = 1
ORDER BY start_date;
```

### Pedidos

```sql
SELECT *
FROM ampev.silver.fato_pedidos_scd2
WHERE PedidoID = 1
  AND EstabelecimentoID = 1
ORDER BY start_date;
```
---
## âš™ï¸ DecisÃµes TÃ©cnicas:

### ğŸ” Uso de Hash
- Evita comparaÃ§Ã£o coluna a coluna. Em vez de comparar cada atributo individualmente (nome, cidade, categoria, valor, etc.), geramos um hash (ex.: _attr_hash) a partir da concatenaÃ§Ã£o dos atributos relevantes.

**Como funciona na prÃ¡tica?**
- Selecionamos apenas os atributos de negÃ³cio, concatenamos os valores (normalizados) e Aplicamos uma funÃ§Ã£o de hash (ex.: sha2)
- Dessa forma, armazenamos como '_attr_hash' em coluna. Se o hash mudou entÃ£o houve alteraÃ§Ã£o real nos dados â†’ aplica SCD2
- Se o hash Ã© igual entÃ£o nenhuma mudanÃ§a relevante â†’ nÃ£o cria nova versÃ£o

#### Data Sentinela
`9999-12-31` representa registros vigentes.

#### âœ” is_current
Facilita filtros e melhora performance.

#### âœ” Delta Lake
Permite:
- MERGE
- UPDATE
- Time Travel
- Controle transacional

### Versionamento via branch: DEV

A branch dev representa o ambiente de desenvolvimento e testes do projeto.
O propÃ³sito da `Branch dev` Ã© desenvolver novas features (ex: nova lÃ³gica SCD2), testar transformaÃ§Ãµes (Bronze â†’ Silver â†’ Gold)
ajustar notebooks e Jobs do Databricks, validar performance e regras de qualidade. Ela funciona como um ambiente seguro, onde mudanÃ§as podem ser feitas sem impactar a produÃ§Ã£o.
---

### ğŸš€ BenefÃ­cios

- HistÃ³rico completo
- Auditoria Bronze â†’ Silver
- Performance otimizada
- CompatÃ­vel com modelagem dimensional
- Pronto para camada Gold

---

### ğŸ“Œ PrÃ³ximo Passo

Camada Gold:
- Fato consolidado
- Join com dimensÃ£o SCD2
- MÃ©tricas agregadas
- Performance otimizada

---

**Projeto:** AMPEV  
**Camada:** Silver  
**PadrÃ£o:** Delta Lake + SCD Type 2  

ğŸ“ˆ Roadmap EstratÃ©gico
ğŸ”¹ PrÃ³xima Fase â€“ Silver Layer

ConversÃ£o data_venda para DateType

Join entre pedidos e estabelecimentos

Tratamento de dados invÃ¡lidos

DeduplicaÃ§Ã£o

ğŸ”¹ Fase Gold

KPIs

MÃ©tricas agregadas

Camada para BI / Power BI

ğŸ”¹ Melhorias Futuras

Alertas automÃ¡ticos

Testes de qualidade de dados

CI/CD com branches dev/main

Monitoramento de SLA