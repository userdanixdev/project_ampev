## project_ampev

## ğŸ“Š Projeto AMPEV â€“ Pipeline de IngestÃ£o com Azure Databricks

### ğŸ§­ Executive Summary:

Este projeto implementa um pipeline de ingestÃ£o incremental utilizando Azure Databricks, Unity Catalog e Delta Lake, seguindo a arquitetura Medallion (Bronze â†’ Silver â†’ Gold).

#### Contexto de NegÃ³cio (AMPEV â€” Fabricantes de Bebidas)

A AMPEV atua como fabricante e distribuidora de bebidas, atendendo uma rede de estabelecimentos clientes (varejo, atacado, bares, mercados e distribuidores regionais). No dia a dia, a gestÃ£o comercial precisa acompanhar demanda, desempenho de portfÃ³lio e concentraÃ§Ã£o de receita para tomar decisÃµes rÃ¡pidas sobre produÃ§Ã£o, logÃ­stica, negociaÃ§Ã£o e estratÃ©gia de vendas.

Dentro desse cenÃ¡rio, as Ã¡reas de Vendas, Comercial e Planejamento fazem perguntas recorrentes para entender:

Quem sÃ£o os principais clientes (para priorizaÃ§Ã£o de atendimento, condiÃ§Ãµes comerciais e retenÃ§Ã£o);

Quais produtos tÃªm maior giro (para planejamento de estoque/produÃ§Ã£o e reposiÃ§Ã£o);

Quais produtos geram mais receita (para decisÃµes de preÃ§o, mix, campanhas e margem).

Essas anÃ¡lises precisam ser respondidas com base em dados confiÃ¡veis e padronizados, evitando divergÃªncias entre relatÃ³rios. Por isso, na arquitetura do lakehouse, a camada GOLD concentra as visÃµes analÃ­ticas prontas para consumo (BI/relatÃ³rios), unificando os dados tratados na Silver em um modelo orientado ao negÃ³cio.

A camada Bronze jÃ¡ estÃ¡ totalmente operacional, com:

- IngestÃ£o incremental via Auto Loader (cloudFiles)
- GovernanÃ§a com Unity Catalog
- Controle de schema explÃ­cito
- Metadados de ingestÃ£o
- ExecuÃ§Ã£o automatizada via Jobs
- Versionamento com GitHub (Databricks Repos)

### ğŸ—ï¸ Arquitetura:
```
Volumes (Landing Zone)
        â†“
Auto Loader (cloudFiles)
        â†“
Delta Tables (Bronze Layer - Unity Catalog)
        â†“
(Silver Layer - futura etapa)
```

### ğŸ“ Estrutura do Volume:

Volume utilizado:

> /Volumes/ampev/bronze/landings

**Estrutura organizada:**

```
landings/
â”‚
â”œâ”€â”€ estabelecimentos/
â”œâ”€â”€ pedidos/
â”‚
â”œâ”€â”€ samples/
â”‚   â”œâ”€â”€ estabelecimentos/
â”‚   â””â”€â”€ pedidos/
â”‚
â”œâ”€â”€ _schemas/
â”‚   â”œâ”€â”€ estabelecimentos/
â”‚   â””â”€â”€ pedidos/
â”‚
â””â”€â”€ _checkpoints/
    â”œâ”€â”€ estabelecimentos/
    â””â”€â”€ pedidos/
```

### ğŸ“¦ Dados Ingeridos
 ### ğŸ“„ estabelecimentos.csv

| Campo             | Tipo   |
| ----------------- | ------ |
| Local             | String |
| Email             | String |
| EstabelecimentoID | Long   |
| Telefone          | String |


### ğŸ“„ pedidos.csv:

| Campo              | Tipo                                |
| ------------------ | ----------------------------------- |
| PedidoID           | Long                                |
| EstabelecimentoID  | Long                                |
| Produto            | String                              |
| quantidade_vendida | Long                                |
| Preco_Unitario     | Double                              |
| data_venda         | String (futura conversÃ£o para Date) |



### âš™ï¸ Tecnologias Utilizadas:

- Azure Databricks
- Unity Catalog
- Delta Lake
- Auto Loader (cloudFiles)
- GitHub (via Databricks Repos)
- Jobs (Workflows)

### ğŸ”„ EstratÃ©gia de IngestÃ£o:

> Auto Loader separado por entidade:

- Cada entidade possui: 
        - Pasta exclusiva
        - SchemaLocation exclusivo
        - Checkpoint exclusivo
        - Tabela Delta exclusiva

```Isso evita mistura de dados e garante isolamento.```

> Schema congelado (bootstrap controlado):

Os schemas foram inferidos a partir de arquivos sample e posteriormente congelados usando StructType(...), garantindo:

- Controle de tipos
- Estabilidade do pipeline
- Evitar inferÃªncia automÃ¡tica incorreta
- Permitir validaÃ§Ã£o futura de mudanÃ§as de layout

### Metadados de ingestÃ£o explÃ­cito:

Durante o writeStream sÃ£o adicionadas colunas tÃ©cnicas:

- ```_ingest_ts``` â†’ timestamp da ingestÃ£o
- ```_source_file``` â†’ caminho do arquivo original (via _metadata.file_path)

### ğŸš€ ExecuÃ§Ã£o do Pipeline:

> Pipeline executado via Databricks Job agendado.

```
ConfiguraÃ§Ã£o recomendada:
Trigger: Scheduled
FrequÃªncia: a cada 10 minutos
Trigger type: availableNow=True
```

> Fluxo:

- Arquivo Ã© colocado na pasta landing
- Job executa
- Auto Loader processa apenas novos arquivos
- Dados sÃ£o gravados na Bronze
- Job encerra

### ğŸ” GovernanÃ§a (Unity Catalog)

As tabelas sÃ£o criadas em:

 - ampev.bronze.estabelecimentos
 - ampev.bronze.pedidos

### ğŸ” Auditoria do Pipeline:

Foi implementado script de auditoria automÃ¡tica para validaÃ§Ã£o de:

- ExistÃªncia da tabela
- Quantidade de registros
- PresenÃ§a de metadados
- HistÃ³rico Delta
- ExistÃªncia de checkpoint


### ğŸ§ª Controle de ExecuÃ§Ã£o:

O pipeline nÃ£o inicia se a pasta estiver vazia:

> has_files(path)

Isso evita:

- Erros de inferÃªncia
- CriaÃ§Ã£o de checkpoint vazio
- ExecuÃ§Ãµes desnecessÃ¡rias

## ğŸ”„ Controle de Versionamento:

IntegraÃ§Ã£o via Databricks Repos:

> Repos/<usuario>/<repositorio>


Fluxo:

- Clone do repositÃ³rio GitHub
- Commit & Push via UI do Databricks


### ğŸ“Œ Boas PrÃ¡ticas Aplicadas:

- SeparaÃ§Ã£o por entidade
- Schema explÃ­cito
- Uso de checkpoints dedicados
- Uso de _metadata.file_path
- ExecuÃ§Ã£o via Job
- Estrutura padronizada de diretÃ³rios
- Auditoria automatizada

### ğŸ“ˆ PrÃ³ximos Passos (Roadmap):

- Implementar camada Silver 
- NormalizaÃ§Ã£o de tipos (converter data_venda para DateType)
- Criar branch strategy (dev/main)

### ğŸ¯ Status Atual:

- âœ… Volume criado
- âœ… Estrutura organizada
- âœ… Auto Loader configurado
- âœ… Schema congelado
- âœ… WriteStream configurado
- âœ… Job configurado
- âœ… IntegraÃ§Ã£o com Git funcionando

Pipeline Bronze operacional.

### ğŸ“¦ Camada Silver â€” ImplementaÃ§Ã£o SCD Type 2

### Objetivo

Implementar controle de histÃ³rico (Slowly Changing Dimension Type 2) nas tabelas da camada Silver:

- `ampev.silver.dim_estabelecimentos_scd2`
- `ampev.silver.fato_pedidos_scd2`

A soluÃ§Ã£o garante:

- HistÃ³rico completo de alteraÃ§Ãµes
- Rastreabilidade Bronze â†’ Silver
- Controle temporal
- ComparaÃ§Ã£o eficiente via hash
- Compatibilidade com modelagem dimensional (Gold)

---

### ğŸ— Arquitetura Geral

```
Bronze (raw ingest)
        â†“
Staging (padronizaÃ§Ã£o + deduplicaÃ§Ã£o + hash)
        â†“
Silver SCD2 (Delta Lake)
```
---

### ğŸ¢ Tabela DimensÃ£o â€” Estabelecimentos (SCD2)

### Tabela:

```sql
ampev.silver.dim_estabelecimentos_scd2
```

### ğŸ”‘ Chave de NegÃ³cio:

```
EstabelecimentoID
```

### ğŸ§± Estrutura

```sql
CREATE TABLE ampev.silver.dim_estabelecimentos_scd2 (
  surrogate_key BIGINT GENERATED ALWAYS AS IDENTITY,

  EstabelecimentoID BIGINT,
  Local STRING,
  Email STRING,
  Telefone STRING,

  start_date DATE,
  end_date DATE,
  is_current BOOLEAN,

  _attr_hash STRING,
  _bronze_ingest_ts TIMESTAMP,
  _bronze_source_file STRING,
  _silver_ts TIMESTAMP
)
USING DELTA;
```

---

### ğŸ”„ LÃ³gica SCD2 â€” DimensÃ£o

### ğŸ†• Novo Estabelecimento
```
Quando '_is_new' = TRUE, significa que o 'EstabelecimentoID' ainda nÃ£o existe na dimensÃ£o (silver.dim_estabelecimentos_scd2).
Ou seja, estamos lidando com um registro totalmente novo, e nÃ£o com uma atualizaÃ§Ã£o.
```

- `_is_new = TRUE`
- Insere nova linha:
  - `start_date = current_date()` -> Data em que o registro passa a ser vÃ¡lido
  - `end_date = 9999-12-31` ->  -> Data futura simbÃ³lica indicando que o registro estÃ¡ ativo
  - `is_current = TRUE` -> Indica que esta Ã© a versÃ£o atual do estabelecimento

> No caso de um novo estabelecimento nÃ£o hÃ¡ histÃ³rico anterior. Ele jÃ¡ nasce como a versÃ£o vigente. Futuras alteraÃ§Ãµes gerarÃ£o novas > > > versÃµes, preservando essa original.  

---

### ğŸ” AlteraÃ§Ã£o de Atributo

```
Quando o '_attr_hash' Ã© diferente, significa que algum atributo relevante do estabelecimento foi alterado (ex: nome, cidade, categoria, etc.). Nesse caso, nÃ£o sobrescrevemos o registro antigo. Aplicamos a estratÃ©gia de SCD Type 2, preservando o histÃ³rico.
Se `_attr_hash` for diferente fecha a versÃ£o atual:  - `end_date = current_date() - 1` e  - `is_current se torna 'FALSE'
e insere nova versÃ£o com dados atualizados.
```
---

### ğŸ“Š Exemplo HistÃ³rico

| EstabelecimentoID | Email | start_date | end_date | is_current |
|------------------|--------|------------|----------|------------|
| 1 | antigo@email.com | 2026-02-01 | 2026-02-10 | FALSE |
| 1 | novo@email.com   | 2026-02-11 | 9999-12-31 | TRUE |

---

### ğŸ§¾ Tabela Fato â€” Pedidos (SCD2)

### Tabela

```sql
ampev.silver.fato_pedidos_scd2
```

### ğŸ”‘ Chave de NegÃ³cio (Composta)

```
(PedidoID, EstabelecimentoID)
```

---

### ğŸ§± Estrutura:

```sql
CREATE TABLE ampev.silver.fato_pedidos_scd2 (
  surrogate_key BIGINT GENERATED ALWAYS AS IDENTITY,

  PedidoID BIGINT,
  EstabelecimentoID BIGINT,
  Produto STRING,
  quantidade_vendida BIGINT,
  Preco_Unitario DOUBLE,
  data_venda DATE,

  start_date DATE,
  end_date DATE,
  is_current BOOLEAN,

  _attr_hash STRING,
  _bronze_ingest_ts TIMESTAMP,
  _bronze_source_file STRING,
  _silver_ts TIMESTAMP
)
USING DELTA;
```
---
### ğŸ§¹ Staging

```A etapa de staging serve para deixar a fonte â€œprontaâ€ antes de aplicar regras de negÃ³cio (ex: SCD2). Aqui a ideia Ã© padronizar, limpar e criar colunas tÃ©cnicas que facilitem o processamento.
```

- `Tipagem correta` -> Garanta que cada coluna esteja no tipo esperado (ex.: PedidoID/EstabelecimentoID como numÃ©rico, quantidade como inteiro/decimal, etc.). Isso evita erro de join, comparaÃ§Ã£o, agregaÃ§Ã£o e escrita.
- ConversÃ£o `data_venda` â†’ DATE
- DeduplicaÃ§Ã£o via `row_number()` com chave composta -> Como podem existir mÃºltiplas versÃµes do mesmo registro na Bronze (reprocessamento/ingestÃµes), vocÃª mantÃ©m apenas a versÃ£o mais recente.
- Hash dos atributos -> Crie um hash (ex.: _attr_hash) com os atributos de negÃ³cio relevantes (excluindo colunas tÃ©cnicas) para detectar mudanÃ§as de forma simples. Se o hash nÃ£o mudou â†’ sem alteraÃ§Ã£o real nos atributos. Se o hash mudou â†’ houve alteraÃ§Ã£o â†’ dispara SCD2 (fechar versÃ£o antiga e criar nova)

---

## ğŸ”„ LÃ³gica SCD2 â€” Fato

### ğŸ†• Novo Pedido

Um pedido Ã© considerado novo quando a chave do registro nÃ£o existe entre os registros vigentes (is_current = TRUE) da sua tabela fato SCD2 (ex.: silver.fato_pedidos_scd2). EntÃ£o Ã© inserido como versÃ£o vigente.

---

### ğŸ” Pedido Alterado

> Quando `_attr_hash` for diferente para um registro novo. Ocorer a fecha automÃ¡tica da versÃ£o atual e insere nova versÃ£o

---

## ğŸ“Š Exemplo HistÃ³rico

| PedidoID | EstabelecimentoID | Produto | start_date | end_date | is_current |
|----------|------------------|----------|------------|----------|------------|
| 1 | 1 | Cerveja | 2026-02-01 | 2026-02-10 | FALSE |
| 1 | 1 | Cerveja Premium | 2026-02-11 | 9999-12-31 | TRUE |

---

## ğŸ” Consultas de HistÃ³rico

### Estabelecimentos

```sql
SELECT *
FROM ampev.silver.dim_estabelecimentos_scd2
WHERE EstabelecimentoID = 1
ORDER BY start_date;
```

### Pedidos

```sql
SELECT *
FROM ampev.silver.fato_pedidos_scd2
WHERE PedidoID = 1
  AND EstabelecimentoID = 1
ORDER BY start_date;
```
---
## âš™ï¸ DecisÃµes TÃ©cnicas:

### ğŸ” Uso de Hash
- Evita comparaÃ§Ã£o coluna a coluna. Em vez de comparar cada atributo individualmente (nome, cidade, categoria, valor, etc.), geramos um hash (ex.: _attr_hash) a partir da concatenaÃ§Ã£o dos atributos relevantes.

**Como funciona na prÃ¡tica?**
- Selecionamos apenas os atributos de negÃ³cio, concatenamos os valores (normalizados) e Aplicamos uma funÃ§Ã£o de hash (ex.: sha2)
- Dessa forma, armazenamos como '_attr_hash' em coluna. Se o hash mudou entÃ£o houve alteraÃ§Ã£o real nos dados â†’ aplica SCD2
- Se o hash Ã© igual entÃ£o nenhuma mudanÃ§a relevante â†’ nÃ£o cria nova versÃ£o

#### Data Sentinela
`9999-12-31` representa registros vigentes.

#### âœ” is_current
Facilita filtros e melhora performance.

#### âœ” Delta Lake
Permite:
- MERGE
- UPDATE
- Time Travel
- Controle transacional

### Versionamento via branch: DEV

A branch dev representa o ambiente de desenvolvimento e testes do projeto.
O propÃ³sito da `Branch dev` Ã© desenvolver novas features (ex: nova lÃ³gica SCD2), testar transformaÃ§Ãµes (Bronze â†’ Silver â†’ Gold)
ajustar notebooks e Jobs do Databricks, validar performance e regras de qualidade. Ela funciona como um ambiente seguro, onde mudanÃ§as podem ser feitas sem impactar a produÃ§Ã£o.
---

### ğŸš€ BenefÃ­cios

- HistÃ³rico completo
- Auditoria Bronze â†’ Silver
- Performance otimizada
- CompatÃ­vel com modelagem dimensional
- Pronto para camada Gold

---

### ğŸ“Œ PrÃ³ximo Passo

Camada Gold:
- Fato consolidado
- Join com dimensÃ£o SCD2
- MÃ©tricas agregadas
- Performance otimizada

---

**Projeto:** AMPEV  
**Camada:** Silver  
**PadrÃ£o:** Delta Lake + SCD Type 2  

### ğŸ¥‡ Camada GOLD â€” AMPEV Lakehouse
#### ğŸ“Œ VisÃ£o Geral

A camada GOLD representa o nÃ­vel analÃ­tico do Lakehouse da AMPEV â€“ Fabricantes de Bebidas.

Enquanto:

- Bronze â†’ IngestÃ£o bruta (Auto Loader)

- Silver â†’ Dados tratados, tipados e com controle histÃ³rico (SCD Type 2)

- Gold â†’ Dados prontos para consumo de negÃ³cio (BI / relatÃ³rios / dashboards)

> A GOLD consolida as informaÃ§Ãµes atravÃ©s de joins entre Fato e DimensÃ£o, aplicando regras de negÃ³cio e agregaÃ§Ãµes para responder perguntas estratÃ©gicas do gerente comercial.

### ğŸ¯ Objetivo de NegÃ³cio

A camada GOLD foi construÃ­da para responder Ã s seguintes perguntas estratÃ©gicas:

- Quais sÃ£o as 5 empresas que mais compraram nossos produtos?
- Quais sÃ£o os 5 produtos mais vendidos?
- Quais sÃ£o os 5 produtos que mais geraram faturamento?

Essas respostas suportam decisÃµes relacionadas a planejamento de produÃ§Ã£o, estratÃ©gia comercial, gestÃ£o de clientes-chave, otimizaÃ§Ã£o de mix de produtos, negociaÃ§Ã£o e retenÃ§Ã£o de grandes compradores.

### ğŸ— Arquitetura da GOLD

A camada GOLD Ã© construÃ­da a partir das tabelas SCD2 da Silver:

> silver.fato_pedidos_scd2

> silver.dim_estabelecimentos_scd2

**Somente os registros vigentes (is_current = TRUE) sÃ£o considerados nas anÃ¡lises atuais.**

### ğŸ”„ View Base AnalÃ­tica
> ampev.gold.vw_vendas_atual

ResponsÃ¡vel por:

- Realizar o JOIN entre fato e dimensÃ£o
- Calcular mÃ©tricas (ex: valor_total)
- Entregar dataset limpo para agregaÃ§Ãµes

**Estrutura lÃ³gica:**
```
FROM silver.fato_pedidos_scd2 p
LEFT JOIN silver.dim_estabelecimentos_scd2 e
  ON p.EstabelecimentoID = e.EstabelecimentoID
 AND e.is_current = TRUE
WHERE p.is_current = TRUE
```
> MÃ©trica derivada:
- valor_total = quantidade_vendida * Preco_Unitario

### ğŸ“Š Views AnalÃ­ticas (Top 5)
#### ğŸ† Top 5 Empresas que Mais Compraram

Baseado em:

- Soma de unidades vendidas
- Soma de faturamento total

Entrega:

- IdentificaÃ§Ã£o dos principais clientes
- Apoio Ã  estratÃ©gia comercial

### ğŸ¥¤Top 5 Produtos Mais Vendidos

Baseado em:

Som>  de quantidade_vendida

Entrega:

- IdentificaÃ§Ã£o de produtos com maior giro
- Suporte ao planejamento de estoque

#### ğŸ’° Top 5 Produtos com Maior Faturamento

Baseado em:

> Soma de valor_total

Entrega:

- IdentificaÃ§Ã£o dos produtos com maior impacto financeiro
- Apoio a decisÃµes de precificaÃ§Ã£o

#### ğŸ§  DecisÃ£o TÃ©cnica Importante
```
Uso de registros vigentes (is_current = TRUE)
Como a Silver utiliza SCD Type 2, existem mÃºltiplas versÃµes histÃ³ricas.
A GOLD utiliza apenas `is_current = TRUE`
Isso garante que as anÃ¡lises representem o estado atual do negÃ³cio.
Caso seja necessÃ¡rio anÃ¡lise histÃ³rica, pode-se remover esse filtro e trabalhar com start_date e end_date.
```

### âš™ï¸ Boas PrÃ¡ticas Aplicadas

- SeparaÃ§Ã£o clara entre camada histÃ³rica (Silver) e analÃ­tica (Gold)
- MÃ©tricas calculadas na camada de consumo
- Views reutilizÃ¡veis para BI

**Estrutura pronta para integraÃ§Ã£o com:**
- Power BI
- Databricks SQL Dashboard
- Jobs agendados

### ğŸš€ Resultado

A camada GOLD transforma dados transacionais em insights estratÃ©gicos, permitindo que a AMPEV tenha:

- VisÃ£o clara dos principais clientes
- Controle sobre produtos de maior giro
- Monitoramento do faturamento por produto
- Base sÃ³lida para tomada de decisÃ£o

### ğŸ“Š Dashboard Executivo â€” Databricks SQL

> O Dashboard Executivo foi desenvolvido no Databricks SQL com o objetivo de transformar os dados consolidados na camada GOLD em insights visuais para tomada de decisÃ£o gerencial.

Ele responde diretamente Ã s principais perguntas do gerente da AMPEV:

- Quais sÃ£o as 5 empresas que mais compraram?
- Quais sÃ£o os 5 produtos mais vendidos?
- Quais sÃ£o os 5 produtos que mais geraram faturamento?

### ğŸ— Arquitetura do Dashboard

Fonte de dados:
```
ampev.gold.vw_vendas_atual
ampev.gold.top5_empresas_mais_compraram
ampev.gold.top5_produtos_mais_vendidos
ampev.gold.top5_produtos_maior_faturamento
```

Fluxo de dados:

> Bronze â†’ Silver (SCD2) â†’ Gold (Views AnalÃ­ticas) â†’ Dashboard

### ğŸ“ˆ VisualizaÃ§Ãµes Implementadas
- Top 5 Empresas por Faturamento
- Tipo: Bar Chart
- MÃ©trica: ``total_faturamento``
- DimensÃ£o: estabelecimento

> Objetivo: Identificar principais clientes da AMPEV

- Top 5 Produtos Mais Vendidos
- Tipo: Bar Chart
- MÃ©trica: ``total_unidades`` 
- DimensÃ£o: produto

Ob> jetivo: Identificar produtos com maior giro

- Top 5 Produtos por Faturamento:

- Tipo: Bar Chart
- MÃ©trica: total_faturamento
- DimensÃ£o: produto

> Objetivo: Identificar produtos com maior impacto financeiro

- **KPIs (Cards Executivos)**
```
Total de Faturamento Geral
Total de Unidades Vendidas
Total de Pedidos
```
> Esses indicadores permitem visÃ£o rÃ¡pida da performance comercial.

### ğŸ”„ AtualizaÃ§Ã£o dos Dados
```
O dashboard estÃ¡ conectado diretamente Ã s views da camada GOLD.
Sempre que a camada Bronze recebe novos dados, a Silver aplica transformaÃ§Ã£o e SCD2 e a Gold recalcula as views
O Dashboard reflete automaticamente os dados atualizados.
```

Pode ser configurado:

Refresh manual
Refresh agendado
IntegraÃ§Ã£o com Databricks Jobs

### ğŸ“¦ Versionamento no GitHub

O repositÃ³rio inclui:

```
/dashboards/ampev_dashboard.json
/docs/images/dashboard_top5_empresas.png
/docs/images/dashboard_produtos.png
```

> JSON exportado do Databricks SQL Dashboard
> Screenshots das visualizaÃ§Ãµes
> DocumentaÃ§Ã£o tÃ©cnica

```Isso garante reprodutibilidade e governanÃ§a do projeto.```

### ğŸš€ Valor EstratÃ©gico:

O Dashboard Executivo transforma dados transacionais em uma visÃ£o clara dos principais clientes, controle sobre os produtos mais estratÃ©gicos e monitoramento contÃ­nuo de faturamento. Base confiÃ¡vel para decisÃµes comerciais

Ele representa a camada final de entrega do projeto Lakehouse da AMPEV, conectando engenharia de dados Ã  estratÃ©gia de negÃ³cio.


ğŸ“ˆ Roadmap EstratÃ©gico
ğŸ”¹ PrÃ³xima Fase â€“ Silver Layer

ConversÃ£o data_venda para DateType

Join entre pedidos e estabelecimentos

Tratamento de dados invÃ¡lidos

DeduplicaÃ§Ã£o

ğŸ”¹ Fase Gold

KPIs

MÃ©tricas agregadas

Camada para BI / Power BI

ğŸ”¹ Melhorias Futuras

Alertas automÃ¡ticos

Testes de qualidade de dados

CI/CD com branches dev/main

Monitoramento de SLA